1. `The vast majority of statistical analysis is not performed by statisticians
<http://simplystatistics.org/2013/06/14/the-vast-majority-of-statistical-analysis-is-not-performed-by-statisticians/>`__

Let me fish out one paragraph:

     [I]n 1967 Stanley Milgram did an experiment to determine the number of
     degrees of separation between two people in the U.S. In his experiment he
     sent 296 letters to people in Omaha, Nebraska and Wichita, Kansas. The
     goal was to get the letters to a specific person in Boston, Massachusetts.
     The trick was people had to send the letters to someone they knew, and
     they then sent it to someone they knew and so on. At the end of the
     experiment, only 64 letters made it to the individual in Boston. On
     average, the letters had gone through 6 people to get there. This is where
     the idea of “6-degrees of Kevin Bacon” comes from. Based on 64 data
     points.  A 2007 study updated that number to “7 degrees of Kevin Bacon”.
     The study was based on 30 billion instant messaging conversations
     collected over the course of a month or two with the same amount of effort

What really jumps at me is how close the values were between the 1967
experiment (with so few datapoints, immensily biased: they only took the ones
that got there!) and the 2007 version (whose conclusion is actually **6.6**).

2. `Odds ratio vs. risk ratio <http://understandinguncertainty.org/how-can-2-become-20>`__

Scientists being misleading, tabloids being misled.

I assume that the author's question of "why is this still allowed?" is
rhethorical. His analysis answers the question: if we only allowed honest
reporting in epidemiology, epidemiological papers would be much less
interesting to the tabloids.

3. A bit old, but interesting: `Peer reviews on PLoS One paper take reviews public
<http://www.plosone.org/article/comments/info:doi%2F10.1371%2Fjournal.pone.0064967>`__

4. Speaking of scientists (particularly public health "scientists") behaving
badly: one of my top scientific peeves is the over-selling of weak results in
public health, especially in nutrition. I think this is more damaging to the
cause of evidence based policy than almost any anti-science group. Many people
will say things like "I don't trust scientists: first it was don't eat olive
oil, now olive oil is good. No peanuts, yes to peanuts, now no to peanuts
again; science is just whatever is fashionable, really." [#]_

So, I was happy to see `Nature telling a Harvard Medical School nutricionist to
shut up
<http://www.forbes.com/sites/trevorbutterworth/2013/05/27/top-science-journal-rebukes-harvards-top-nutritionist/>`__
and stop mangling the science for "public benefit".

.. [#] One really good comment from a non-scientist friend: "until I met you
   and your scientist friends, I was mostly exposed to science through news
   reports of the sort of studies that now I realise all the other scientists
   sneer at." We need to sneer more. (Yes, I have non-scientist friends; who'd
   have known?)

5. `Please stop putting the figures at the end of the manuscript
<http://corticalia.wordpress.com/2013/04/17/letter-to-editor/>`__

I have never heard anyone defend the current system of figures at the end of
the manuscript (except on *that's the way it always was* grounds).

Computers & networks normally have a two step impact on systems: (1) reproduce
the old paper based procedures in digital form, and (2) reshape the procedures
to be native. Science publishing is still stuck on step 1.

